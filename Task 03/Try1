% Directory containing the files
dataDir = 'C:\Users\ASUS\Documents\Computer Science @Plymuni . NSBM\3rd Year\AI and ML\Coursework\New folder';

% Filter for .mat files
files = dir(fullfile(dataDir, '*.mat'));
if isempty(files)
    error('No .mat files found in the directory. Please check the file extensions or path.');
else
    disp(['Number of .mat files found: ', num2str(length(files))]);
end

% Initialize variables
data_groups = containers.Map('KeyType', 'double', 'ValueType', 'any');

% Load and group data by feature count
for i = 1:length(files)
    filePath = fullfile(files(i).folder, files(i).name);
    disp(['Processing file: ', files(i).name]);
    
    % Load the data
    try
        data = load(filePath);
    catch ME
        disp(['Error loading file: ', files(i).name, ' - ', ME.message]);
        continue;
    end
    
    % Get field names in the .mat file
    featureKey = fieldnames(data);
    if isempty(featureKey)
        disp(['Skipping file: ', files(i).name, ' - No fields found in the data.']);
        continue;
    end
    disp(['Fields in the file: ', files(i).name]);
    disp(featureKey);

    % Access the first field (assuming it contains features)
    try
        features = data.(featureKey{1});
    catch
        disp(['Skipping file: ', files(i).name, ' - Unable to access the first field.']);
        continue;
    end

    % Validate features
    if isempty(features) || ~isnumeric(features)
        disp(['Skipping file: ', files(i).name, ' - Data is empty or not numeric.']);
        continue;
    end
    
    % Group by feature count
    feature_count = size(features, 2); % Number of features (columns)
    if ~isKey(data_groups, feature_count)
        data_groups(feature_count) = features;
    else
        data_groups(feature_count) = [data_groups(feature_count); features];
    end
end

% Train and evaluate MLP for each feature group
feature_keys = keys(data_groups);
for k = 1:length(feature_keys)
    feature_count = feature_keys{k};
    dataset = data_groups(feature_count);
    
    disp(['Training MLP for ', num2str(feature_count), '-feature dataset...']);
    
    % Split data into training and testing sets
    [n_samples, n_features] = size(dataset);
    labels = randi([0, 1], n_samples, 1); % Example: Generate random binary labels
    
    % Shuffle data
    perm = randperm(n_samples);
    dataset = dataset(perm, :);
    labels = labels(perm, :);

    % 80% training, 20% testing
    train_ratio = 0.8;
    n_train = round(train_ratio * n_samples);
    train_data = dataset(1:n_train, :);
    train_labels = labels(1:n_train);
    test_data = dataset(n_train+1:end, :);
    test_labels = labels(n_train+1:end);

    % PCA for dimensionality reduction
    [coeff, train_data_pca, ~, ~, explained] = pca(train_data);
    cumulativeVariance = cumsum(explained);
    pca_idx = find(cumulativeVariance >= 95, 1); % Retain 95% variance
    train_data_pca = train_data_pca(:, 1:pca_idx);
    test_data_pca = test_data * coeff(:, 1:pca_idx);
    
    % Step 3: Cross-Validated Training and Tuning
    hidden_layer_sizes = [5, 10, 20]; % Number of neurons to test
    activation_functions = {'logsig', 'tansig', 'purelin'};
    best_accuracy = 0;
    best_net = [];
    
    for h = 1:length(hidden_layer_sizes)
        for a = 1:length(activation_functions)
            % Create and configure MLP
            net = feedforwardnet(hidden_layer_sizes(h));
            net.layers{1}.transferFcn = activation_functions{a};
            net.trainParam.showWindow = false; % Suppress GUI
            net.divideParam.trainRatio = 0.8; % Train
            net.divideParam.valRatio = 0.1;   % Validation
            net.divideParam.testRatio = 0.1;  % Test
            
            % Add L2 regularization
            net.performParam.regularization = 0.1; % Regularization parameter
            
            % Train with cross-validation
            net = train(net, train_data_pca', train_labels'); % Transpose for MATLAB format
            
            % Evaluate on test set
            predictions = net(test_data_pca')';
            predictions = round(predictions); % Convert outputs to binary for comparison
            accuracy = mean(predictions == test_labels);
            
            disp(['Hidden neurons: ', num2str(hidden_layer_sizes(h)), ', Activation: ', activation_functions{a}, ...
                  ', Accuracy: ', num2str(accuracy * 100), '%']);
            
            % Track the best model
            if accuracy > best_accuracy
                best_accuracy = accuracy;
                best_net = net;
            end
        end
    end
    
    % Display best model results
    disp(['Best model for ', num2str(feature_count), '-feature dataset:']);
    disp(['Accuracy: ', num2str(best_accuracy * 100), '%']);
end
